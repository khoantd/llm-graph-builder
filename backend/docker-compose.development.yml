version: '3.8'

services:
  backend:
    image: llm-graph-builder-backend:latest
    container_name: llm-graph-builder-backend-dev
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - PORT=8000
      - NODE_ENV=development
      - DEBUG=true
    volumes:
      # Local bind mounts for development
      - ./data:/code/data
      - ./chunks:/code/chunks
      - ./merged_files:/code/merged_files
      - ./logs:/code/logs
      - ./cache:/code/cache
      - ./uploads:/code/uploads
      - ./models:/code/models
      - ./temp:/code/temp
      
      # Source code for live reloading (optional)
      - ./src:/code/src
      - ./score.py:/code/score.py
      
      # Configuration files
      - ./example.env:/code/example.env:ro
      - ./.env:/code/.env:ro
      
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "2"
